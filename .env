# --- LLM(vLLM/OpenAI 호환) ---
OPENAI_API_KEY=local-anything
OPENAI_BASE_URL=http://172.16.10.168:9993/v1
OPENAI_MODEL=qwen3-30b-a3b-fp8

# --- RAG 인덱스/업로드/청킹 ---
INDEX_DIR=faiss_index
UPLOAD_DIR=uploads
DATA_CSV=data/민생.csv
CHUNK_SIZE=800
CHUNK_OVERLAP=120

# 임베딩
EMBEDDING_MODEL=BAAI/bge-m3
EMBEDDING_DEVICE=cpu
E5_USE_PREFIX=0

# (옵션) 재랭커
ENABLE_RERANKER=true
RERANKER_MODEL=BAAI/bge-reranker-base
RERANKER_TOP_N=5

# --- (프론트 직접 호출 시) CORS 허용 원본 ---
CORS_ORIGINS=http://172.16.10.168:3000,http://localhost:3000

# 하이브리드/힌트/검색 파라미터
ENABLE_SPARSE=1
SPARSE_LIMIT=200
SPACE_FILTER_MODE=soft
SPACE_HINT_BONUS=0.25
RETRIEVER_K=5
RETRIEVER_FETCH_K=64
SEARCH_TYPE=mmr
PAGE_FILTER_MODE=hard
PAGE_HINT_BONUS=0.7
TITLE_BONUS=0.25
STICKY_AFTER_MCP=true

# 링크/보안
ALLOWED_SOURCE_HOSTS=confluence.nuriflex.co.kr
CONFLUENCE_BASE_URL=https://confluence.nuriflex.co.kr

# 같은 docker 네트워크에서 서비스명과 컨테이너 포트를 쓰는 경우:
MCP_URL=http://mcp-confluence:9000/sse

# 프로토콜 버전 & 툴 고정
MCP_PROTOCOL_VERSION=2025-06-18
CONFLUENCE_MCP_TOOL=search_pages

# 타임아웃/언어 기본값
MCP_TIMEOUT=5
SEARCH_LANGS=ko,en