# rag-router/app.py
from fastapi import FastAPI
from pydantic import BaseModel
from typing import List, Optional
import os, httpx, time, uuid, re, math
from html import unescape
from datetime import datetime
from zoneinfo import ZoneInfo

RAG = os.getenv("RAG_PROXY_URL", "http://rag-proxy:8080")
OPENAI = os.getenv("OPENAI_URL", "http://172.16.10.168:9993/v1")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "qwen3-30b-a3b-fp8")
ROUTER_MODEL_ID = os.getenv("ROUTER_MODEL_ID", "qwen3-30b-a3b-fp8-router")
TZ = os.getenv("ROUTER_TZ", "Asia/Seoul")
_NUM_ONLY_LINE = re.compile(r'(?m)^\s*(\d{1,3}(?:,\d{3})*|\d+)\s*$')

ROUTER_MAX_TOKENS = int(os.getenv("ROUTER_MAX_TOKENS", "2048"))
ANSWER_MODE = os.getenv("ROUTER_ANSWER_MODE", "auto")
BULLETS_MAX = int(os.getenv("ROUTER_BULLETS_MAX", "15"))
MAX_CTX_CHARS = int(os.getenv("MAX_CTX_CHARS", "8000"))
_BULLET_HINTS = os.getenv(
    "ROUTER_AUTO_BULLET_HINTS",
    "ì •ë¦¬ ìš”ì•½ í•­ëª© ëª©ë¡ ë¦¬ìŠ¤íŠ¸ ë¶ˆë¦¿ bullet ì²´í¬ë¦¬ìŠ¤íŠ¸ ì¥ë‹¨ì  ë¹„êµ í¬ì¸íŠ¸ í•µì‹¬ todo í•´ì•¼í• ì¼"
).split()
_PARA_HINTS = os.getenv(
    "ROUTER_AUTO_PARA_HINTS",
    "ì„¤ëª… ìì„¸íˆ ì•Œë ¤ì¤˜ ì†Œê°œ ë¬´ì—‡ ë­ì•¼ í•´ì¤˜ ì™œ ì–´ë–»ê²Œ ì˜ë¯¸ ì •ì˜ ê°œìš” í•œë¬¸ë‹¨ ë¬¸ë‹¨ ì„œìˆ í˜•"
).split()

# [ì¶”ê°€] ì œëª© ì ‘ë‘ì–´ ì™„ì „ ë¹„í™œì„±(ê¸°ë³¸ ""), í•„ìš”ì‹œ í™˜ê²½ë³€ìˆ˜ë¡œ ì¼œë„ ë¨
HEADING = os.getenv("ROUTER_HEADING", "")

# [ì¶”ê°€] ì¶œì²˜ í‘œì‹œ on/off ë° ìµœëŒ€ ê°œìˆ˜
ROUTER_SHOW_SOURCES = (os.getenv("ROUTER_SHOW_SOURCES", "1").lower() not in ("0","false","no"))
ROUTER_SOURCES_MAX  = int(os.getenv("ROUTER_SOURCES_MAX", "5"))

# === relevance gate ===
_KO_EN_TOKEN = re.compile(r"[A-Za-z0-9]+|[ê°€-í£]{2,}")

SYNONYMS = {
    "NIA": ["í•œêµ­ì§€ëŠ¥ì •ë³´ì‚¬íšŒì§„í¥ì›", "ì§€ëŠ¥ì •ë³´ì‚¬íšŒì§„í¥ì›", "êµ­ê°€ì •ë³´í™”ì§„í¥ì›"],
    "ìƒê°€ì •ë³´": ["ìƒê¶Œì •ë³´", "ìƒê¶Œ ë¶„ì„", "ìƒê¶Œ", "ìƒì—…ìš© ë¶€ë™ì‚° ì •ë³´", "ìƒê°€ ë§¤ë¬¼"]
}

_STOPWORDS = set("""
ì€ ëŠ” ì´ ê°€ ì„ ë¥¼ ì— ì˜ ì™€ ê³¼ ë„ ë¡œ ìœ¼ë¡œ ì—ì„œ ì—ê²Œ ê·¸ë¦¬ê³  ê·¸ëŸ¬ë‚˜ ê·¸ë˜ì„œ
ë¬´ì—‡ ë­ì•¼ ë­ì§€ ì„¤ëª… í•´ì¤˜ ëŒ€í•œ ëŒ€í•´ ì •ë¦¬ ê°œìš” ì†Œê°œ ìì„¸íˆ
""".split())

def _tokens(s: str) -> list[str]:
    return [t.lower() for t in _KO_EN_TOKEN.findall(s or "")]

def relevance_ratio(q: str, ctx: str, ctx_limit: int = 2000) -> float:
    qk = [t for t in _tokens(q) if t not in _STOPWORDS]
    if not qk:
        return 0.0
    ck = set(_tokens((ctx or "")[:ctx_limit]))
    common = sum(1 for t in qk if t in ck)
    return common / len(qk)

# í™˜ê²½ë³€ìˆ˜ë¡œ ë¬¸í„±ê°’ ì¡°ì • ê°€ëŠ¥ (ê¸°ë³¸ 0.2)
REL_THRESH = float(os.getenv("ROUTER_MIN_OVERLAP", "0.08"))

def is_relevant(q: str, ctx: str) -> bool:
    return relevance_ratio(q, ctx) >= REL_THRESH

def _is_webui_task(s: str) -> bool:
    return bool(re.match(r"(?is)^\s*#{3}\s*task\s*:", (s or "")))

app = FastAPI()

class Msg(BaseModel):
    role: str
    content: str

class ChatReq(BaseModel):
    model: str
    messages: List[Msg]
    stream: Optional[bool] = False
    max_tokens: Optional[int] = None

def strip_reasoning(text: str) -> str:
    if not text: return text
    text = re.sub(r'(?is)<think>.*?</think>\s*', '', text)
    text = re.sub(r'(?is)<\|assistant_thought\|>.*?(?=<\|assistant_response\|>|\Z)', '', text)
    text = re.sub(r'(?is)<\|assistant_response\|>', '', text)
    text = re.sub(r'(?im)^\s*(thought|reasoning)\s*:\s*.*?(?:\n\n|\Z)', '', text)
    return text.strip()

def mark_lonely_numbers_as_total(text: str) -> str:
    """
    ì¤„ ì „ì²´ê°€ ìˆ«ìë§Œìœ¼ë¡œ ì´ë£¨ì–´ì§„ ê²½ìš° '(í•©ê³„: N)'ìœ¼ë¡œ ë°”ê¿”
    LLMì´ ê°œë³„ í•­ëª© ìˆ˜ì¹˜ë¡œ ì˜¤í•´í•˜ì§€ ì•Šë„ë¡ íŒíŠ¸ë¥¼ ì¤€ë‹¤.
    """
    def repl(m: re.Match):
        n = m.group(1)
        return f"(í•©ê³„: {n})"
    return _NUM_ONLY_LINE.sub(repl, text)

# [ì¶”ê°€] ì»¨í…ìŠ¤íŠ¸ê°€ 'ëª©ë¡ìŠ¤ëŸ¬ì›€'ì„ ë³´ì´ëŠ”ì§€ ê°€ë³ê²Œ ìŠ¤ì½”ì–´ë§
def _looks_structured(ctx: str) -> bool:
    if not ctx: return False
    lines = [ln.strip() for ln in ctx.splitlines() if ln.strip()]
    if len(lines) < 4:  # ì¤„ì´ ì ìœ¼ë©´ êµ³ì´ ë¶ˆë¦¿ ì•„ë‹˜
        return False
    bullet_like = 0
    for ln in lines[:40]:  # ì²« 40ì¤„ë§Œ ê²€ì‚¬
        if re.match(r"^(?:[-â€¢*]\s+|\d+\.\s+|\[\w+\]\s+)", ln):
            bullet_like += 1
        elif len(ln) <= 28:  # ì§§ì€ ë‹¨ë¬¸ì´ ë§ì´ ì´ì–´ì§€ë©´ ëª©ë¡ì¼ í™•ë¥  â†‘
            bullet_like += 0.5
    # ëŒ€ëµ 4ì  ì´ìƒì´ë©´ ëª©ë¡ìŠ¤ëŸ½ë‹¤ê³  íŒë‹¨
    return bullet_like >= 4

# [ì¶”ê°€] ì‚¬ìš©ì ì§ˆë¬¸ + ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì¶œë ¥ ëª¨ë“œ ê²°ì •
def pick_answer_mode(user_msg: str, ctx_text: str) -> str:
    # í™˜ê²½ë³€ìˆ˜ë¡œ ëª¨ë“œë¥¼ ê°•ì œí•œ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
    if ANSWER_MODE != "auto":
        return ANSWER_MODE

    um = (user_msg or "").lower()
    # ëª…ì‹œ íŒíŠ¸ ìš°ì„ 
    if any(k.lower() in um for k in _BULLET_HINTS):
        return "bulleted"
    if any(k.lower() in um for k in _PARA_HINTS):
        return "paragraph"

    # ë¬¸ì„œê°€ ëª©ë¡ êµ¬ì¡°ì´ë©´ ë¶ˆë¦¿, ì•„ë‹ˆë©´ ë¬¸ë‹¨
    return "bulleted" if _looks_structured(ctx_text) else "paragraph"

# --- utils ----------------------------------------------------

def normalize_query(q: str) -> str:
    if not q: return ""
    s = q.strip()
    # s = re.sub(r'(?i)\bstep\b', 'SFTP', s)
    s = re.sub(r'(?i)\bstfp\b|\bsfttp\b|\bsfpt\b|\bsftp\b', 'SFTP', s)
    s = s.replace("ìŠ¤í…", "SFTP")
    return s

def _expand_synonyms(s: str) -> list[str]:
    out = [s]
    for k, vs in SYNONYMS.items():
        if k in s:
            for v in vs:
                out.append(s.replace(k, v))
    ss = s.replace("ìƒê°€ ì •ë³´", "ìƒê°€ì •ë³´")
    if ss != s: out.append(ss)
    return list(dict.fromkeys(out))

def generate_query_variants(q: str, limit: int = 12) -> List[str]:
    s = normalize_query(q)
    cand = []
    def add(x): 
        x = re.sub(r'\s+',' ',x).strip()
        if x and x not in cand: cand.append(x)
    add(s); add(re.sub(r'\s+','',s))
    add(re.sub(r'([ê°€-í£])([A-Za-z0-9])', r'\1 \2', s))
    add(re.sub(r'([A-Za-z0-9])([ê°€-í£])', r'\1 \2', s))
    for v in _expand_synonyms(s):
        add(v); add(re.sub(r'\s+','',v))
    # ê¸°ì¡´ pairs ìœ ì§€
    return cand[:limit]

def sanitize(text: str) -> str:
    if not text: return ""
    t = unescape(text.replace("&nbsp;", " "))
    t = re.sub(r'(?i)(password|passwd|pwd|íŒ¨ìŠ¤ì›Œë“œ|ë¹„ë°€ë²ˆí˜¸)\s*[:=]\s*\S+', r'\1: ******', t)
    t = re.sub(r'(?i)(token|secret|key|í‚¤)\s*[:=]\s*[A-Za-z0-9\-_]{6,}', r'\1: <redacted>', t)
    t = re.sub(r'(?i)(account|user(?:name)?|userid|ê³„ì •|ì•„ì´ë””)\s*[:=]\s*\S+', r'\1: <redacted>', t)
    t = re.sub(r'\b(\d{1,3}\.\d{1,3}\.\d{1,3})\.\d{1,3}\b', r'\1.xxx', t)
    return t

def build_system_with_context(ctx_text: str, mode: str) -> str:
    if mode == "bulleted":
        style = (
            f"- ìµœëŒ€ {BULLETS_MAX}ê°œ ë¶ˆë¦¿ìœ¼ë¡œ **êµ¬ì²´ì **ìœ¼ë¡œ ì„œìˆ í•œë‹¤.\n"
            "- ê° ë¶ˆë¦¿ì€ 2~4ë¬¸ì¥ìœ¼ë¡œ ì“´ë‹¤.\n"
            "- ë¶ˆë¦¿ ì™¸ì˜ êµ°ë”ë”ê¸° ì„œë¡ /ê²°ë¡  ë¬¸ë‹¨ì€ ê¸¸ê²Œ ë„£ì§€ ì•ŠëŠ”ë‹¤.\n"
        )
    elif mode == "sections":
        style = (
            "- 2~4ê°œì˜ **ë¬¸ë‹¨**ìœ¼ë¡œ í•µì‹¬â†’ë°°ê²½â†’ì„¸ë¶€â†’ì‹œì‚¬ì  ìˆœìœ¼ë¡œ ì •ë¦¬í•œë‹¤.\n"
            "- ë§ˆí¬ë‹¤ìš´ ë¦¬ìŠ¤íŠ¸ ë¬¸ë²•ì€ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤.\n"
        )
    else:  # paragraph
        style = (
            "- **ë¦¬ìŠ¤íŠ¸/ë²ˆí˜¸/í•˜ì´í”ˆ(-, â€¢, 1.) ì—†ì´** í•œë‘ ê°œì˜ **ì—°ì†ëœ ë¬¸ë‹¨**ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•œë‹¤.\n"
            "- ì²« ë¬¸ì¥ì— ê°œë…/ìš”ì§€ë¥¼ ë¶„ëª…íˆ ë§í•˜ê³ , ì´ì–´ì„œ êµ¬ì„±ìš”ì†ŒÂ·ë™ì‘Â·ì¥ì /ì œì•½ì„ ë§¤ë„ëŸ½ê²Œ ì„¤ëª…í•œë‹¤.\n"
        )

    # ğŸ”’ ìˆ«ì/ìˆ˜ì¹˜ ì¸ìš© ê°€ë“œë ˆì¼(í•µì‹¬!)
    numeric_rules = (
        "- í‘œ/ëª©ë¡ì— ìˆëŠ” **ìˆ˜ì¹˜(ì˜ˆ: ë‹¨ì§€ ìˆ˜)** ëŠ” **ê°™ì€ í–‰(ê°™ì€ í•­ëª©)** ì— ì íŒ ìˆ«ìë§Œ ì¸ìš©í•œë‹¤.\n"
        "- **í•©ê³„/ì´ê³„/ìš”ì•½ ìˆ«ì**(í–‰ ì´ë¦„ì´ ë¹„ê±°ë‚˜ ìƒìœ„ êµ¬ ë‹¨ìœ„ì— ë¶™ì€ ìˆ˜ì¹˜)ëŠ” **ê°œë³„ í•­ëª©ì˜ ê°’ìœ¼ë¡œ ë°°ì •í•˜ì§€ ì•ŠëŠ”ë‹¤.**\n"
        "- íŠ¹ì • í•­ëª©ì˜ ìˆ˜ì¹˜ê°€ ë¶ˆëª…í™•í•˜ë©´ **ìˆ«ìë¥¼ ì“°ì§€ ë§ê³ ** 'ìˆ˜ì¹˜ ë¶ˆë¶„ëª…'ìœ¼ë¡œ í‘œí˜„í•œë‹¤.\n"
        "- ìˆ«ìë¥¼ ì“¸ ë•ŒëŠ” ë°˜ë“œì‹œ `í•­ëª©ëª… ìˆ«ì`ë¡œ **ìŒì„ ì´ë¤„** ì„œìˆ í•œë‹¤. (ì˜ˆ: `ë°˜í¬ë™ 47`)\n"
        "- ìƒìœ„ ë‹¨ìœ„ í•©ê³„ëŠ” í•„ìš” ì‹œ `(ì„œì´ˆêµ¬ í•©ê³„ 439)`ì²˜ëŸ¼ **í•©ê³„ì„ì„ ëª…ì‹œ**í•œë‹¤.\n"
    )

    heading_hint = (f"- ê°€ëŠ¥í•˜ë©´ '{HEADING}' ì•„ë˜ë¡œ ì •ë¦¬í•œë‹¤.\n" if HEADING else "")
    return (
        "ì—­í• : ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê·¼ê±°ë¡œ **ì •í™•í•˜ê³  ì‹¤ë¬´ ì¹œí™”ì ì¸** í•œêµ­ì–´ ë‹µë³€ì„ ì‘ì„±í•œë‹¤.\n"
        "ì›ì¹™:\n"
        "- ì»¨í…ìŠ¤íŠ¸ì— ìˆëŠ” ì •ë³´ë§Œ ì‚¬ìš©í•˜ê³  ì¶”ì¸¡/í™˜ê° ê¸ˆì§€.\n"
        "- ìˆ˜ì¹˜Â·ì •ì±…Â·ê³ ìœ ëª…ì‚¬ëŠ” ê°€ëŠ¥í•˜ë©´ ê·¸ëŒ€ë¡œ ì¸ìš©í•˜ë˜ ê³¼ë„í•œ ë°˜ë³µì€ í”¼í•œë‹¤.\n"
        "- ë‚´ë¶€ ì¶”ë¡ (<think> ë“±) ì¶œë ¥ ê¸ˆì§€, ìµœì¢… ë‹µë§Œ ì¶œë ¥í•œë‹¤.\n"
        + heading_hint + style + numeric_rules +
        "- ì»¨í…ìŠ¤íŠ¸ê°€ ì™„ì „íˆ ë¹„ì—ˆê±°ë‚˜ ë¬´ê´€í•˜ë©´ ì •í™•íˆ `ì¸ë±ìŠ¤ì— ê·¼ê±° ì—†ìŒ`ë§Œ ì¶œë ¥í•œë‹¤.\n"
        "- ë¯¼ê°ì •ë³´(ë¹„ë°€ë²ˆí˜¸/í† í°/IP ë§ˆì§€ë§‰ ì˜¥í…Ÿ)ëŠ” ë§ˆìŠ¤í‚¹í•œë‹¤.\n"
        "[ì»¨í…ìŠ¤íŠ¸ ì‹œì‘]\n"
        f"{ctx_text}\n"
        "[ì»¨í…ìŠ¤íŠ¸ ë]\n"
    )



def extract_texts(items: List[dict]) -> List[str]:
    texts = []
    for it in items or []:
        for key in ("text","content","chunk","snippet","body","page_text"):
            val = it.get(key)
            if isinstance(val,str) and val.strip():
                texts.append(unescape(val.strip())); break
        else:
            payload = it.get("payload") or it.get("data") or {}
            if isinstance(payload,dict):
                for key in ("text","content","body"):
                    val = payload.get(key)
                    if isinstance(val,str) and val.strip():
                        texts.append(unescape(val.strip())); break
    return texts

# [ì¶”ê°€] URL ì •ê·œí™”(Confluence pageId ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±°)
def _normalize_url(u: str) -> str:
    if not u:
        return ""
    u = str(u).split("#")[0].strip().rstrip("/")
    m = re.search(r"(pageId=\d+)", u)
    if m:
        base = u.split("?")[0]
        return f"{base}?{m.group(1)}"
    return u

# [êµì²´] ê°€ì¥ ê´€ë ¨ë„ ë†’ì€ URLë¶€í„° dedup í›„ ìƒìœ„ Nê°œë§Œ
def _collect_urls_from_items(items: List[dict], top_n: Optional[int] = None) -> List[str]:
    top_n = top_n or ROUTER_SOURCES_MAX
    cands = []

    def push(it: dict):
        if not isinstance(it, dict):
            return
        score = float(it.get("score") or it.get("similarity") or 0.0)

        # 1) ìµœìš°ì„ : url í•„ë“œ
        url = it.get("url") or it.get("source_url") or it.get("link")
        if url:
            cands.append((score, _normalize_url(str(url))))

        # 2) payload/metadata ì•ˆì˜ url
        payload = it.get("payload") or it.get("data") or {}
        if isinstance(payload, dict):
            url2 = payload.get("url") or payload.get("source_url") or payload.get("link")
            if url2:
                cands.append((score, _normalize_url(str(url2))))

        meta = it.get("metadata") or {}
        if isinstance(meta, dict):
            url3 = meta.get("url")
            if url3:
                cands.append((score, _normalize_url(str(url3))))

            # [ADD] URLì´ ì „í˜€ ì—†ìœ¼ë©´, ë¡œì»¬ íŒŒì¼ ê²½ë¡œë¼ë„ ì¶œì²˜ë¡œ ê¸°ë¡
            #       (uploads/xxx.pdf ê°™ì€ ê²½ë¡œê°€ ì‚¬ìš©ìì—ê²Œë„ ìœ ìš©)
            if not (url or (payload if isinstance(payload, dict) else {}).get("url") or url3):
                src = meta.get("source")
                if src:
                    cands.append((score, str(src)))  # â† ê·¸ëŒ€ë¡œ í‘œì‹œ (ex: uploads/ë¬¸ì„œ.pdf)

    for it in items or []:
        push(it)

    # score ë‚´ë¦¼ì°¨ìˆœ, ì¤‘ë³µ ì œê±°
    cands = [(s, u) for (s, u) in cands if u]
    cands.sort(key=lambda x: x[0], reverse=True)

    out: List[str] = []
    for _, u in cands:
        if u not in out:
            out.append(u)
        if len(out) >= top_n:
            break
    return out

def is_good_context_for_qa(ctx: str) -> bool:
    if not ctx or not ctx.strip(): return False
    if len(ctx) < 180: return False
    if ctx.count("\n") < 2: return False
    return True

@app.get("/v1/models")
def models():
    return {"object": "list", "data": [{"id": ROUTER_MODEL_ID, "object": "model"}]}

@app.post("/v1/chat/completions")
async def chat(req: ChatReq):
    orig_user_msg = next((m.content for m in reversed(req.messages) if m.role == "user"), "").strip()
    variants = generate_query_variants(orig_user_msg)

    # â˜… ë©”íƒ€ íƒœìŠ¤í¬ë©´ RAG ê±´ë„ˆë›°ê³  ê·¸ëŒ€ë¡œ ëª¨ë¸ë¡œ ì „ë‹¬ (JSON í˜•ì‹ ë³´ì¡´)
    if _is_webui_task(orig_user_msg):
        payload = {
            "model": OPENAI_MODEL,
            "messages": [m.model_dump() for m in req.messages],  # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€ ê¸ˆì§€
            "stream": False,
            "temperature": 0,
            "max_tokens": req.max_tokens or ROUTER_MAX_TOKENS,
        }
        async with httpx.AsyncClient() as client:
            r = await client.post(f"{OPENAI}/chat/completions", json=payload)
        return r.json()

    ctx_text = ""
    qa_json = None
    qa_items = []
    qa_urls: List[str] = []     # QA ê²½ë¡œ ì¶œì²˜

    timeout = httpx.Timeout(
        connect=20.0,  # TCP ì—°ê²°
        read=120.0,    # ì‘ë‹µ ë°”ë”” ì½ê¸° (ëª¨ë¸ ìƒì„± ì‹œê°„)
        write=60.0,    # ìš”ì²­ ì „ì†¡
        pool=120.0     # ì»¤ë„¥ì…˜ í’€ ëŒ€ê¸°
    )
    async with httpx.AsyncClient(timeout=timeout) as client:
        for v in variants:
            try:
                # sticky ë¹„í™œì„±í™” í”Œë˜ê·¸ ì¶”ê°€
                qa = await client.post(f"{RAG}/qa", json={"q": v, "k": 5, "sticky": False})
                j = qa.json()
            except (httpx.RequestError, ValueError) as e:
                print(f"[router] /qa error for '{v}': {e}")
                continue
            if (j.get("hits") or 0) > 0:
                qa_json = j
                qa_items = j.get("items", [])
                qa_urls = (j.get("source_urls") or _collect_urls_from_items(qa_items))
                break

    # 2-A) QA ì„±ê³µ
    if qa_json:
        ctx_text = "\n\n".join(extract_texts(qa_items))[:MAX_CTX_CHARS]
        ctx_text = mark_lonely_numbers_as_total(ctx_text)
    # [CHANGE] ê¸¸ì´(80ì) í—ˆìš© ì‚­ì œ â†’ ê´€ë ¨ë„/ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆë§Œ
    qa_ok = bool(ctx_text.strip()) and (is_good_context_for_qa(ctx_text) or is_relevant(orig_user_msg, ctx_text))
    if not qa_ok:
        qa_json = None

    if qa_json:
        ctx_for_prompt = sanitize(ctx_text)    
        mode = pick_answer_mode(orig_user_msg, ctx_for_prompt)
        system_prompt = build_system_with_context(ctx_for_prompt, mode)
        max_tokens = req.max_tokens or ROUTER_MAX_TOKENS
        payload = {
            "model": OPENAI_MODEL,
            "messages": [{"role":"system","content":system_prompt}] + [m.model_dump() for m in req.messages],
            "stream": False,
            "temperature": 0,
            "max_tokens": max_tokens,
        }
        async with httpx.AsyncClient(timeout=timeout) as client:
            try:
                r = await client.post(f"{OPENAI}/chat/completions", json=payload)
                rj = r.json()
                raw = rj.get("choices", [{}])[0].get("message", {}).get("content", "") or ""
            except (httpx.RequestError, ValueError) as e:
                print(f"[router] OPENAI chat error: {e}")
                raw = ""

        content = sanitize(strip_reasoning(raw).strip()) or "ì¸ë±ìŠ¤ì— ê·¼ê±° ì—†ìŒ"
        # [ë³€ê²½] í´ë°± ì‹œ ì œëª© ì ‘ë‘ì–´ ì œê±°
        # if content == "ì¸ë±ìŠ¤ì— ê·¼ê±° ì—†ìŒ" and ctx_text.strip():
        #     content = sanitize(ctx_text)[:600]

        # [ì¶”ê°€] ì¶œì²˜ ë¶™ì´ê¸° (MCP/Confluence ê²½ë¡œì¼ ë•Œ)
        if ROUTER_SHOW_SOURCES and qa_urls:
            content += "\n\nì¶œì²˜:\n" + "\n".join(f"- {u}" for u in qa_urls)

        return {
            "id": f"cmpl-{uuid.uuid4()}",
            "object": "chat.completion",
            "created": int(time.time()),
            "model": req.model,
            "choices": [{"index":0,"message":{"role":"assistant","content":content},"finish_reason":"stop"}],
        }

    # 2-B) QA ì‹¤íŒ¨ â†’ QUERY
    best_ctx_good = ""; best_ctx_any = ""
    best_urls_good: List[str] = []     # [ì¶”ê°€]
    best_urls_any: List[str] = []      # [ì¶”ê°€]

    async with httpx.AsyncClient(timeout=timeout) as client:
        for v in variants:
            try:
                # [CHANGE] sticky ë¹„í™œì„±í™” í”Œë˜ê·¸ ì¶”ê°€
                qres = await client.post(f"{RAG}/query", json={"q": v, "k": 5, "sticky": False})
                qj = qres.json()
            except (httpx.RequestError, ValueError) as e:
                print(f"[router] /query error for '{v}': {e}")
                continue

            # [ì¶”ê°€] items/contexts ë“±ì—ì„œ í…ìŠ¤íŠ¸ì™€ URL ëª¨ë‘ ìˆ˜ì§‘
            items = (qj.get("items") or qj.get("contexts") or [])
            urls = (qj.get("source_urls") or _collect_urls_from_items(items))

            ctx_list = (
                qj.get("context_texts")
                or [c.get("text","") for c in (qj.get("contexts") or [])]
                or [it.get("text","") for it in (qj.get("items") or [])]
            )
            ctx = "\n\n---\n\n".join([t for t in ctx_list if t])[:MAX_CTX_CHARS]

            if len(ctx) > len(best_ctx_any):
                best_ctx_any = ctx
                best_urls_any = urls[:]   # [ì¶”ê°€]
            if is_good_context_for_qa(ctx) and len(ctx) > len(best_ctx_good):
                best_ctx_good = ctx
                best_urls_good = urls[:]  # [ì¶”ê°€]

    best_ctx = best_ctx_good or best_ctx_any
    src_urls = best_urls_good or best_urls_any  # [ì¶”ê°€]

    # [CHANGE] ê¸¸ì´(80ì) ì¡°ê±´ ì‚­ì œ â†’ ê´€ë ¨ë„ë§Œ
    if best_ctx and not is_relevant(orig_user_msg, best_ctx):
        best_ctx = ""
        src_urls = []

    if not best_ctx:
        # ì¼ë°˜ LLM í´ë°±
        now_kst = datetime.now(ZoneInfo(TZ)).strftime("%Y-%m-%d (%a) %H:%M:%S %Z")
        sysmsg = {
            "role": "system",
            "content": f"í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„: {now_kst}. ë¬¸ì„œ ì¸ë±ìŠ¤ê°€ ì—†ì–´ë„ ì¼ë°˜ ìƒì‹Â·ìˆ˜í•™Â·ë‚ ì§œ/ì‹œê°„ ë“±ì€ ì§ì ‘ ë‹µí•˜ì„¸ìš”. â€˜ì¸ë±ìŠ¤ì— ê·¼ê±° ì—†ìŒâ€™ ê°™ì€ ë§ì€ í•˜ì§€ ë§ˆì„¸ìš”."
        }
        max_tokens = req.max_tokens or ROUTER_MAX_TOKENS
        payload = {"model": OPENAI_MODEL, "messages": [sysmsg] + [m.model_dump() for m in req.messages],
                   "stream": False, "temperature": 0, "max_tokens": max_tokens}
        async with httpx.AsyncClient(timeout=timeout) as client:
            try:
                r = await client.post(f"{OPENAI}/chat/completions", json=payload)
                rj = r.json()
                raw = rj.get("choices", [{}])[0].get("message", {}).get("content", "") or ""
                content = sanitize(strip_reasoning(raw).strip()) or "ì£„ì†¡í•´ìš”. ì§€ê¸ˆì€ ë‹µì„ ì°¾ì§€ ëª»í–ˆì–´ìš”."
            except (httpx.RequestError, ValueError):
                content = "ì£„ì†¡í•´ìš”. ì§€ê¸ˆì€ ë‹µì„ ì°¾ì§€ ëª»í–ˆì–´ìš”."
        return {
            "id": f"cmpl-{uuid.uuid4()}",
            "object": "chat.completion",
            "created": int(time.time()),
            "model": req.model,
            "choices": [{"index":0,"message":{"role":"assistant","content":content},"finish_reason":"stop"}],
        }

    # QUERY ê²½ë¡œ LLM í˜¸ì¶œ
    ctx_text = best_ctx
    ctx_text = mark_lonely_numbers_as_total(ctx_text) 
    ctx_for_prompt = sanitize(ctx_text)
    mode = pick_answer_mode(orig_user_msg, ctx_for_prompt)
    system_prompt = build_system_with_context(ctx_for_prompt, mode)
    max_tokens = req.max_tokens or ROUTER_MAX_TOKENS
    payload = {
        "model": OPENAI_MODEL,
        "messages":[{"role":"system","content":system_prompt}] + [m.model_dump() for m in req.messages],
        "stream": False, "temperature": 0, "max_tokens": max_tokens
    }
    async with httpx.AsyncClient(timeout=timeout) as client:
        try:
            r = await client.post(f"{OPENAI}/chat/completions", json=payload)
            rj = r.json()
            raw = rj.get("choices", [{}])[0].get("message", {}).get("content", "") or ""
        except (httpx.RequestError, ValueError) as e:
            print(f"[router] OPENAI chat error: {e}")
            raw = ""

    content = sanitize(strip_reasoning(raw).strip()) or "ì¸ë±ìŠ¤ì— ê·¼ê±° ì—†ìŒ"

    # [ë³€ê²½] í´ë°± ì‹œ ì œëª© ì ‘ë‘ì–´ ì œê±°
    # if content == "ì¸ë±ìŠ¤ì— ê·¼ê±° ì—†ìŒ" and ctx_text.strip():
    #     content = sanitize(ctx_text)[:600]

    # [ì¶”ê°€] ì¶œì²˜ ë¶™ì´ê¸°
    if ROUTER_SHOW_SOURCES and src_urls:
        content += "\n\nì¶œì²˜:\n" + "\n".join(f"- {u}" for u in src_urls)

    return {
        "id": f"cmpl-{uuid.uuid4()}",
        "object": "chat.completion",
        "created": int(time.time()),
        "model": req.model,
        "choices": [{"index":0,"message":{"role":"assistant","content":content},"finish_reason":"stop"}],
    }